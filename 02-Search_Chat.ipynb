{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Set this up to support Vector search [previously pip install azure-search-documents==11.4.0b8]\n",
        "#pip install azure-search-documents --pre  \n",
        "\n",
        "#pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1693265379787
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
        "\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1693265304664
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.search.documents import SearchClient  \n",
        "from azure.search.documents.indexes import SearchIndexClient  \n",
        "from azure.search.documents.models import Vector  \n",
        "from azure.search.documents.indexes.models import (  \n",
        "    SearchIndex,  \n",
        "    SearchField,  \n",
        "    SearchFieldDataType,  \n",
        "    SimpleField,  \n",
        "    SearchableField,  \n",
        "    SearchIndex,  \n",
        "    SemanticConfiguration,  \n",
        "    PrioritizedFields,  \n",
        "    SemanticField,  \n",
        "    SearchField,  \n",
        "    SemanticSettings,  \n",
        "    VectorSearch,  \n",
        "    HnswVectorSearchAlgorithmConfiguration,  \n",
        ")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1693265447950
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load config values\n",
        "with open(r'config.json') as config_file:\n",
        "    config_details = json.load(config_file)\n",
        "\n",
        "# Azure OpenAI Resources\n",
        "openai_api_base = config_details['OPENAI_API_BASE']\n",
        "openai_api_key = config_details[\"OPENAI_API_KEY\"]\n",
        "openai_api_version = config_details['OPENAI_API_VERSION']\n",
        "\n",
        "chat_model_deployment = config_details['GPT_MODEL']\n",
        "embeddings_model_deployment = config_details['EMBEDDING_MODEL']\n",
        "\n",
        "# Azure Cognitive Search Resources\n",
        "AZSEARCH_KEY = config_details['AZSEARCH_KEY']\n",
        "AZSEARCH_ENDPOINT= config_details['AZSEARCH_ENDPOINT']\n",
        "AZSEARCH_INDEX_NAME = config_details['AZSEARCH_INDEX_NAME']\n",
        "AZSEARCH_API_VERSION = config_details['AZSEARCH_API_VERSION']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1693265448717
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "openai.api_base = openai_api_base\n",
        "openai.api_key = openai_api_key\n",
        "openai.api_version = openai_api_version\n",
        "openai.api_type = \"azure\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1693265449662
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Establish for connectivity to Azure Cognitive Search throughout\n",
        "credential = AzureKeyCredential(AZSEARCH_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1693265450063
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to Generate Embeddings using OpenAI Ada 002\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "# Function to generate embeddings for use query\n",
        "def generate_embeddings(text):\n",
        "    response = openai.Embedding.create(\n",
        "        input=text, engine=embeddings_model_deployment)\n",
        "    embeddings = response['data'][0]['embedding']\n",
        "    return embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Query Cognitive Search\n",
        "\n",
        "Uses pure vector search to find most relevant documents and format for use in GPT Prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1693267389995
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Azure Media Services is a cloud-based media processing and delivery platform that enables you to build, deploy, and scale video applications. It provides features like encoding, streaming, content protection, and video indexing. Media Services supports various input and output formats, such as MP4, MPEG-DASH, and HLS. You can use Media Services to deliver live and on-demand video, build video-on-demand platforms, and analyze your video content. It also integrates with other Azure services, such as Azure Content Delivery Network and Azure Storage. [Azure Media Services] ^0.8114831',\n",
              " 'Azure Stream Analytics is a real-time data stream processing service that enables you to analyze and process high volumes of fast-moving data. It supports various data sources, such as Azure Event Hubs, Azure IoT Hub, and Azure Blob Storage. Stream Analytics provides features like windowing, time-based aggregations, and user-defined functions. You can use Stream Analytics to build real-time dashboards, detect anomalies, and generate alerts. It also integrates with other Azure services, such as Azure Functions and Azure Machine Learning. [Azure Stream Analytics] ^0.8030056',\n",
              " 'Azure Time Series Insights is a fully managed analytics, storage, and visualization service that enables you to explore and analyze time-series data. It supports various data sources, such as Azure IoT Hub, Azure Event Hubs, and Azure Blob Storage. Time Series Insights provides features like real-time data streaming, advanced querying, and pattern recognition. You can use Time Series Insights to monitor your IoT devices, detect anomalies, and gain insights into your data. It also integrates with other Azure services, such as Azure Stream Analytics and Azure Machine Learning. [Azure Time Series Insights] ^0.7995169',\n",
              " 'Azure Log Analytics is a log management and analytics service that enables you to collect, store, and analyze your log data from various sources, such as Azure resources, custom applications, and operating systems. It provides features like advanced querying, data visualization, and integration with Azure Monitor. Log Analytics supports various data types, such as performance counters, event logs, and custom logs. You can use Azure Log Analytics to detect and diagnose issues, optimize your performance, and ensure the security of your infrastructure. It also integrates with other Azure services, such as Azure Security Center and Azure Application Insights. [Azure Log Analytics] ^0.796361',\n",
              " 'Azure HDInsight is a fully managed, open-source analytics service for processing big data workloads. It provides popular open-source frameworks, such as Apache Hadoop, Apache Spark, Apache Kafka, and Apache HBase. HDInsight supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use HDInsight to analyze and process large volumes of data, build real-time analytics solutions, and develop machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Machine Learning. [Azure HDInsight] ^0.79468995',\n",
              " 'Azure Application Insights is an application performance management service that enables you to monitor, diagnose, and troubleshoot your applications and infrastructure. It provides features like real-time telemetry, dependency mapping, and live metrics. Application Insights supports various platforms, such as .NET, Java, Node.js, and Python. You can use Azure Application Insights to detect and diagnose issues, optimize your performance, and ensure the availability of your applications. It also integrates with other Azure services, such as Azure Monitor and Azure Log Analytics. [Azure Application Insights] ^0.7927271',\n",
              " 'Azure Data Explorer is a fast, fully managed data analytics service for real-time analysis on large volumes of data. It provides features like ingestion, querying, and visualization. Data Explorer supports various data sources, such as Azure Event Hubs, Azure IoT Hub, and Azure Blob Storage. You can use Data Explorer to analyze logs, monitor applications, and gain insights into your data. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Machine Learning. [Azure Data Explorer] ^0.7924891',\n",
              " 'Azure Data Lake Analytics is an on-demand, cloud-based analytics service that enables you to process and analyze big data. It provides features like job scheduling, parallel processing, and built-in analytics functions. Data Lake Analytics supports various data sources, such as Azure Data Lake Storage, Azure Blob Storage, and Azure SQL Database. You can use Data Lake Analytics to run U-SQL, R, and Python scripts, perform advanced analytics, and gain insights into your data. It also integrates with other Azure services, such as Azure Machine Learning and Azure Data Factory. [Azure Data Lake Analytics] ^0.78989744',\n",
              " 'Azure Monitor is a comprehensive, full-stack monitoring service that enables you to collect, analyze, and act on telemetry data from your applications and infrastructure. It provides features like log analytics, metrics, alerts, and dashboards. Azure Monitor supports various data sources, such as Azure resources, custom applications, and operating systems. You can use Azure Monitor to detect and diagnose issues, optimize your performance, and ensure the availability of your resources. It also integrates with other Azure services, such as Azure Log Analytics and Azure Application Insights. [Azure Monitor] ^0.78836256',\n",
              " 'Azure Synapse Analytics is an integrated analytics service that brings together big data and data warehousing. It enables you to ingest, prepare, manage, and serve data for immediate business intelligence and machine learning needs. Synapse Analytics provides a unified workspace for data engineers, data scientists, and business analysts to collaborate and build solutions. It supports various data sources, including Azure Data Lake Storage, Azure Blob Storage, and Azure Cosmos DB. You can use Synapse Analytics with other Azure services, such as Azure Machine Learning and Power BI. [Azure Synapse Analytics] ^0.78826356']"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pure Vector Search\n",
        "query = \"tools for video analysis\"  \n",
        "  \n",
        "search_client = SearchClient(AZSEARCH_ENDPOINT, AZSEARCH_INDEX_NAME, credential=credential)\n",
        "vector = Vector(value=generate_embeddings(query), k=10, fields=\"contentVector\")\n",
        "  \n",
        "results = search_client.search(  \n",
        "    search_text=None,  \n",
        "    vectors= [vector],\n",
        "    select=[\"title\", \"content\", \"category\"],\n",
        ")  \n",
        "  \n",
        "docs_list = []\n",
        "  \n",
        "for result in results:  \n",
        "    # print(f\"Title: {result['title']}\")  \n",
        "    # print(f\"Score: {result['@search.score']}\")  \n",
        "    # print(f\"Text: {result['content']}\")  \n",
        "    # print(f\"Category: {result['category']}\\n\")  \n",
        "    docs_list.append(f\"{result['content']} [{result['title']}] ^{result['@search.score']}\")\n",
        "\n",
        "docs_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Setup ChatGPT Prompt\n",
        "\n",
        "Create the message (prompt) to send to ChatGPT.  With the [Chat Completion API](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions#working-with-the-chat-completion-api) there are distinct sections of the prompt that are sent to the API in the form of an array of dictionaries with associated roles: system, user, and assistant. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1693267040542
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = []\n",
        "\n",
        "#setting up the personality and clear instructions for the assistant\n",
        "system_message = \"You're an Azure Support Specialist helping customers and partners understand the services available. \\\n",
        "You are given a question and a context. You need to answer the question using only the context. \\\n",
        "Be friendly and conversational, don't sound like a computer! \\\n",
        "The context contains information about a service, with the title of the source document enclosed by [] and the relevancy search score follows a ^ \\\n",
        "Format the information from the three most relevant services into a bulleted list. \\\n",
        "If there are no good matches tell the user you cannot find anything, but they can ask again. \\\n",
        "Always include the document title the information was sourced from at the end of each suggestion enclosed in []. \\\n",
        "Do not show the scores to the user.\"\n",
        "\n",
        "prompt.append({\"role\":\"system\", \"content\": system_message})\n",
        "prompt\n",
        "\n",
        "# adding some special instructions and an example\n",
        "prompt.append({\"role\":\"user\", \"content\": f\"Print the document titles at the end of the suggestion enclosed in []\"})\n",
        "prompt.append({\"role\": \"assistant\", \"content\": f\"Azure Stream Analytics is a real-time data stream processing service that enables you to analyze and process high volumes of fast-moving data [Azure Stream Analytics].\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1693267460588
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the information provided, here are three Azure services that can be used for video analysis:\n",
            "\n",
            "- Azure Media Services: This cloud-based platform enables you to build, deploy, and scale video applications. It provides features like encoding, streaming, content protection, and video indexing. You can use Media Services to deliver live and on-demand video, build video-on-demand platforms, and analyze your video content. [Azure Media Services]\n",
            "\n",
            "- Azure Stream Analytics: This real-time data stream processing service allows you to analyze and process high volumes of fast-moving data. It supports various data sources such as Azure Event Hubs, Azure IoT Hub, and Azure Blob Storage. Stream Analytics offers features like windowing, time-based aggregations, and user-defined functions. It can be used to build real-time dashboards, detect anomalies, and generate alerts. [Azure Stream Analytics]\n",
            "\n",
            "- Azure Time Series Insights: This fully managed analytics, storage, and visualization service is designed for exploring and analyzing time-series data. It supports data sources like Azure IoT Hub, Azure Event Hubs, and Azure Blob Storage. Time Series Insights provides features such as real-time data streaming, advanced querying, and pattern recognition. It is useful for monitoring IoT devices, detecting anomalies, and gaining insights into your data. [Azure Time Series Insights]\n",
            "\n",
            "Please note that these suggestions are based on the information provided and there may be other Azure services that can also be used for video analysis.\n"
          ]
        }
      ],
      "source": [
        "# Add the user's search question with the specific context (documents from Azure Search).\n",
        "prompt.append({\"role\":\"user\", \"content\":f\"Question: {query} <context> {docs_list} </context>\"})\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "engine=chat_model_deployment,\n",
        "messages=prompt,\n",
        "temperature=0.7,  #adjust as needed to make more or less random/deterministic\n",
        ")\n",
        "\n",
        "suggestions = completion.choices[0].message['content']\n",
        "print(suggestions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
